{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1a7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d401dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>investment_knowledge</th>\n",
       "      <th>investment_experience</th>\n",
       "      <th>num_assets</th>\n",
       "      <th>time_horizon</th>\n",
       "      <th>goal_type</th>\n",
       "      <th>investment_frequency</th>\n",
       "      <th>dependents</th>\n",
       "      <th>market_sensitivity</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>preferred_asset</th>\n",
       "      <th>education_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>risk_profile</th>\n",
       "      <th>expected_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>10930</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Retirement</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>749613</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>High School</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>4285</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Retirement</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1609455</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>High School</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>4095</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Education</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>762546</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>17704</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Wealth Accumulation</td>\n",
       "      <td>Yearly</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>137805</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>19705</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>Wealth Accumulation</td>\n",
       "      <td>Yearly</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1879055</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  monthly_income  investment_knowledge  investment_experience  \\\n",
       "0   56           10930                     7                     16   \n",
       "1   69            4285                     4                     16   \n",
       "2   46            4095                     5                      0   \n",
       "3   32           17704                     9                      0   \n",
       "4   60           19705                     7                      8   \n",
       "\n",
       "   num_assets  time_horizon            goal_type investment_frequency  \\\n",
       "0           2            10           Retirement              Monthly   \n",
       "1           4            10           Retirement            Quarterly   \n",
       "2           4            21            Education              Monthly   \n",
       "3           2            18  Wealth Accumulation               Yearly   \n",
       "4           9            21  Wealth Accumulation               Yearly   \n",
       "\n",
       "   dependents  market_sensitivity  net_worth preferred_asset education_level  \\\n",
       "0           0                   5     749613     Real Estate     High School   \n",
       "1           4                   2    1609455          Crypto     High School   \n",
       "2           1                   2     762546           Mixed         Masters   \n",
       "3           3                   5     137805          Crypto         Masters   \n",
       "4           3                   9    1879055           Bonds       Bachelors   \n",
       "\n",
       "  employment_type risk_profile  expected_return  \n",
       "0        Salaried  Speculative             2.68  \n",
       "1         Retired  Speculative             2.00  \n",
       "2      Unemployed  Speculative             3.70  \n",
       "3        Salaried     Moderate             2.00  \n",
       "4         Retired  Speculative             3.82  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"investor_risk_return_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28d7517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>investment_knowledge</th>\n",
       "      <th>investment_experience</th>\n",
       "      <th>num_assets</th>\n",
       "      <th>time_horizon</th>\n",
       "      <th>dependents</th>\n",
       "      <th>market_sensitivity</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>expected_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.539400</td>\n",
       "      <td>10569.431400</td>\n",
       "      <td>5.47560</td>\n",
       "      <td>9.581900</td>\n",
       "      <td>5.026500</td>\n",
       "      <td>15.023500</td>\n",
       "      <td>2.002000</td>\n",
       "      <td>4.978600</td>\n",
       "      <td>1.003934e+06</td>\n",
       "      <td>3.366692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.911636</td>\n",
       "      <td>5510.965004</td>\n",
       "      <td>2.85724</td>\n",
       "      <td>5.713734</td>\n",
       "      <td>2.571198</td>\n",
       "      <td>8.392091</td>\n",
       "      <td>1.413717</td>\n",
       "      <td>3.161794</td>\n",
       "      <td>5.703640e+05</td>\n",
       "      <td>0.958894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.055000e+03</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>5782.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.234820e+05</td>\n",
       "      <td>2.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>10586.500000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.002044e+06</td>\n",
       "      <td>3.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>15431.250000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.488106e+06</td>\n",
       "      <td>4.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>19998.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.999981e+06</td>\n",
       "      <td>6.910000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  monthly_income  investment_knowledge  \\\n",
       "count  10000.000000    10000.000000           10000.00000   \n",
       "mean      43.539400    10569.431400               5.47560   \n",
       "std       14.911636     5510.965004               2.85724   \n",
       "min       18.000000     1002.000000               1.00000   \n",
       "25%       31.000000     5782.000000               3.00000   \n",
       "50%       43.000000    10586.500000               5.00000   \n",
       "75%       56.000000    15431.250000               8.00000   \n",
       "max       69.000000    19998.000000              10.00000   \n",
       "\n",
       "       investment_experience    num_assets  time_horizon    dependents  \\\n",
       "count           10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean                9.581900      5.026500     15.023500      2.002000   \n",
       "std                 5.713734      2.571198      8.392091      1.413717   \n",
       "min                 0.000000      1.000000      1.000000      0.000000   \n",
       "25%                 5.000000      3.000000      8.000000      1.000000   \n",
       "50%                10.000000      5.000000     15.000000      2.000000   \n",
       "75%                15.000000      7.000000     22.000000      3.000000   \n",
       "max                19.000000      9.000000     29.000000      4.000000   \n",
       "\n",
       "       market_sensitivity     net_worth  expected_return  \n",
       "count        10000.000000  1.000000e+04     10000.000000  \n",
       "mean             4.978600  1.003934e+06         3.366692  \n",
       "std              3.161794  5.703640e+05         0.958894  \n",
       "min              0.000000  5.055000e+03         2.000000  \n",
       "25%              2.000000  5.234820e+05         2.610000  \n",
       "50%              5.000000  1.002044e+06         3.310000  \n",
       "75%              8.000000  1.488106e+06         4.030000  \n",
       "max             10.000000  1.999981e+06         6.910000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5e2572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      0\n",
       "monthly_income           0\n",
       "investment_knowledge     0\n",
       "investment_experience    0\n",
       "num_assets               0\n",
       "time_horizon             0\n",
       "goal_type                0\n",
       "investment_frequency     0\n",
       "dependents               0\n",
       "market_sensitivity       0\n",
       "net_worth                0\n",
       "preferred_asset          0\n",
       "education_level          0\n",
       "employment_type          0\n",
       "risk_profile             0\n",
       "expected_return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4260e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd7f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['goal_type'] = le.fit_transform(data['goal_type'])\n",
    "data['investment_frequency'] = le.fit_transform(data['investment_frequency'])\n",
    "data['preferred_asset'] = le.fit_transform(data['preferred_asset'])\n",
    "data['education_level'] = le.fit_transform(data['education_level'])\n",
    "data['employment_type'] = le.fit_transform(data['employment_type'])\n",
    "data['risk_profile'] = le.fit_transform(data['risk_profile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad5c9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>investment_knowledge</th>\n",
       "      <th>investment_experience</th>\n",
       "      <th>num_assets</th>\n",
       "      <th>time_horizon</th>\n",
       "      <th>goal_type</th>\n",
       "      <th>investment_frequency</th>\n",
       "      <th>dependents</th>\n",
       "      <th>market_sensitivity</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>preferred_asset</th>\n",
       "      <th>education_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>risk_profile</th>\n",
       "      <th>expected_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>10930</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>749613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>4285</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1609455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>4095</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>762546</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>17704</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>137805</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>19705</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1879055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  monthly_income  investment_knowledge  investment_experience  \\\n",
       "0   56           10930                     7                     16   \n",
       "1   69            4285                     4                     16   \n",
       "2   46            4095                     5                      0   \n",
       "3   32           17704                     9                      0   \n",
       "4   60           19705                     7                      8   \n",
       "\n",
       "   num_assets  time_horizon  goal_type  investment_frequency  dependents  \\\n",
       "0           2            10          2                     0           0   \n",
       "1           4            10          2                     1           4   \n",
       "2           4            21          0                     0           1   \n",
       "3           2            18          3                     2           3   \n",
       "4           9            21          3                     2           3   \n",
       "\n",
       "   market_sensitivity  net_worth  preferred_asset  education_level  \\\n",
       "0                   5     749613                3                1   \n",
       "1                   2    1609455                1                1   \n",
       "2                   2     762546                2                2   \n",
       "3                   5     137805                1                2   \n",
       "4                   9    1879055                0                0   \n",
       "\n",
       "   employment_type  risk_profile  expected_return  \n",
       "0                2             3             2.68  \n",
       "1                1             3             2.00  \n",
       "2                3             3             3.70  \n",
       "3                2             2             2.00  \n",
       "4                1             3             3.82  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035da3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>investment_knowledge</th>\n",
       "      <th>investment_experience</th>\n",
       "      <th>num_assets</th>\n",
       "      <th>time_horizon</th>\n",
       "      <th>goal_type</th>\n",
       "      <th>investment_frequency</th>\n",
       "      <th>dependents</th>\n",
       "      <th>market_sensitivity</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>preferred_asset</th>\n",
       "      <th>education_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>risk_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>10930</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>749613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>4285</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1609455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>4095</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>762546</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>17704</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>137805</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>19705</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1879055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>55</td>\n",
       "      <td>9456</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1846674</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>51</td>\n",
       "      <td>7331</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>758730</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57</td>\n",
       "      <td>14107</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1645259</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>64</td>\n",
       "      <td>10494</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>720632</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>32</td>\n",
       "      <td>14853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29456</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  monthly_income  investment_knowledge  investment_experience  \\\n",
       "0      56           10930                     7                     16   \n",
       "1      69            4285                     4                     16   \n",
       "2      46            4095                     5                      0   \n",
       "3      32           17704                     9                      0   \n",
       "4      60           19705                     7                      8   \n",
       "...   ...             ...                   ...                    ...   \n",
       "9995   55            9456                     5                     19   \n",
       "9996   51            7331                     8                     10   \n",
       "9997   57           14107                     9                     10   \n",
       "9998   64           10494                     9                      7   \n",
       "9999   32           14853                     1                      0   \n",
       "\n",
       "      num_assets  time_horizon  goal_type  investment_frequency  dependents  \\\n",
       "0              2            10          2                     0           0   \n",
       "1              4            10          2                     1           4   \n",
       "2              4            21          0                     0           1   \n",
       "3              2            18          3                     2           3   \n",
       "4              9            21          3                     2           3   \n",
       "...          ...           ...        ...                   ...         ...   \n",
       "9995           6            20          2                     2           4   \n",
       "9996           6            29          3                     2           2   \n",
       "9997           8            24          0                     1           1   \n",
       "9998           7            23          3                     0           0   \n",
       "9999           8            12          3                     2           2   \n",
       "\n",
       "      market_sensitivity  net_worth  preferred_asset  education_level  \\\n",
       "0                      5     749613                3                1   \n",
       "1                      2    1609455                1                1   \n",
       "2                      2     762546                2                2   \n",
       "3                      5     137805                1                2   \n",
       "4                      9    1879055                0                0   \n",
       "...                  ...        ...              ...              ...   \n",
       "9995                   7    1846674                1                2   \n",
       "9996                   6     758730                0                2   \n",
       "9997                   4    1645259                3                1   \n",
       "9998                   9     720632                0                3   \n",
       "9999                   0      29456                4                3   \n",
       "\n",
       "      employment_type  risk_profile  \n",
       "0                   2             3  \n",
       "1                   1             3  \n",
       "2                   3             3  \n",
       "3                   2             2  \n",
       "4                   1             3  \n",
       "...               ...           ...  \n",
       "9995                1             3  \n",
       "9996                0             3  \n",
       "9997                2             3  \n",
       "9998                3             3  \n",
       "9999                2             1  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['expected_return'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c7af4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.68\n",
       "1       2.00\n",
       "2       3.70\n",
       "3       2.00\n",
       "4       3.82\n",
       "        ... \n",
       "9995    3.42\n",
       "9996    4.15\n",
       "9997    2.85\n",
       "9998    5.80\n",
       "9999    2.75\n",
       "Name: expected_return, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['expected_return']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2deeaf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expected_return\n",
       "2.00    1096\n",
       "2.97      52\n",
       "3.49      49\n",
       "3.74      48\n",
       "3.53      47\n",
       "        ... \n",
       "6.34       1\n",
       "6.28       1\n",
       "6.32       1\n",
       "6.58       1\n",
       "5.99       1\n",
       "Name: count, Length: 429, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8490c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5899487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78adbe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f43f3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 15), (2000, 15))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape,x_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962341d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37ce349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train_scaled.shape[1],)), \n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=MeanSquaredError(), \n",
    "    metrics=['mae']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76523b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1388fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"tensorflowlogs\"\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f88452ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cb =  EarlyStopping(monitor='val_loss', patience=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32834f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(filepath='best_model.h5',monitor='val_loss',save_best_only=True,save_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcaf3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 53/225\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0109 - mae: 2.6896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:202: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=self._current_epoch, batch=batch, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 4.8225 - mae: 1.7674 - val_loss: 1.0694 - val_mae: 0.8331\n",
      "Epoch 2/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4821 - mae: 0.9742 - val_loss: 0.9969 - val_mae: 0.8026\n",
      "Epoch 3/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2095 - mae: 0.8805 - val_loss: 1.0132 - val_mae: 0.8046\n",
      "Epoch 4/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0879 - mae: 0.8396 - val_loss: 0.9680 - val_mae: 0.7885\n",
      "Epoch 5/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0056 - mae: 0.8056 - val_loss: 0.9452 - val_mae: 0.7808\n",
      "Epoch 6/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9701 - mae: 0.8009 - val_loss: 0.9211 - val_mae: 0.7734\n",
      "Epoch 7/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9348 - mae: 0.7844 - val_loss: 0.9000 - val_mae: 0.7742\n",
      "Epoch 8/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9311 - mae: 0.7856 - val_loss: 0.9512 - val_mae: 0.7858\n",
      "Epoch 9/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9166 - mae: 0.7792 - val_loss: 0.9152 - val_mae: 0.7750\n",
      "Epoch 10/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9032 - mae: 0.7758 - val_loss: 0.8807 - val_mae: 0.7647\n",
      "Epoch 11/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8897 - mae: 0.7712 - val_loss: 0.9247 - val_mae: 0.7817\n",
      "Epoch 12/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8868 - mae: 0.7686 - val_loss: 0.9011 - val_mae: 0.7748\n",
      "Epoch 13/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8768 - mae: 0.7639 - val_loss: 0.8831 - val_mae: 0.7696\n",
      "Epoch 14/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8602 - mae: 0.7577 - val_loss: 0.8899 - val_mae: 0.7702\n",
      "Epoch 15/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8532 - mae: 0.7515 - val_loss: 0.8981 - val_mae: 0.7715\n",
      "Epoch 16/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8799 - mae: 0.7643 - val_loss: 0.8875 - val_mae: 0.7682\n",
      "Epoch 17/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8753 - mae: 0.7624 - val_loss: 0.8904 - val_mae: 0.7767\n",
      "Epoch 18/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8644 - mae: 0.7616 - val_loss: 0.8869 - val_mae: 0.7727\n",
      "Epoch 19/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8474 - mae: 0.7541 - val_loss: 0.8949 - val_mae: 0.7769\n",
      "Epoch 20/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8477 - mae: 0.7537 - val_loss: 0.8890 - val_mae: 0.7699\n",
      "Epoch 21/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8620 - mae: 0.7591 - val_loss: 0.8848 - val_mae: 0.7691\n",
      "Epoch 22/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8540 - mae: 0.7557 - val_loss: 0.8836 - val_mae: 0.7701\n",
      "Epoch 23/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8831 - mae: 0.7702 - val_loss: 0.8805 - val_mae: 0.7674\n",
      "Epoch 24/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8453 - mae: 0.7531 - val_loss: 0.8813 - val_mae: 0.7658\n",
      "Epoch 25/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8418 - mae: 0.7480 - val_loss: 0.8796 - val_mae: 0.7683\n",
      "Epoch 26/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8563 - mae: 0.7592 - val_loss: 0.8743 - val_mae: 0.7591\n",
      "Epoch 27/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8542 - mae: 0.7528 - val_loss: 0.8777 - val_mae: 0.7637\n",
      "Epoch 28/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8873 - mae: 0.7695 - val_loss: 0.8790 - val_mae: 0.7647\n",
      "Epoch 29/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8502 - mae: 0.7538 - val_loss: 0.8915 - val_mae: 0.7757\n",
      "Epoch 30/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8434 - mae: 0.7470 - val_loss: 0.8829 - val_mae: 0.7675\n",
      "Epoch 31/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8477 - mae: 0.7515 - val_loss: 0.8768 - val_mae: 0.7656\n",
      "Epoch 32/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8418 - mae: 0.7457 - val_loss: 0.8814 - val_mae: 0.7654\n",
      "Epoch 33/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8290 - mae: 0.7440 - val_loss: 0.8915 - val_mae: 0.7708\n",
      "Epoch 34/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8357 - mae: 0.7450 - val_loss: 0.8855 - val_mae: 0.7707\n",
      "Epoch 35/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8556 - mae: 0.7530 - val_loss: 0.8729 - val_mae: 0.7611\n",
      "Epoch 36/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8373 - mae: 0.7495 - val_loss: 0.8751 - val_mae: 0.7610\n",
      "Epoch 37/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8094 - mae: 0.7367 - val_loss: 0.8761 - val_mae: 0.7630\n",
      "Epoch 38/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8225 - mae: 0.7370 - val_loss: 0.8726 - val_mae: 0.7625\n",
      "Epoch 39/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8324 - mae: 0.7435 - val_loss: 0.8895 - val_mae: 0.7710\n",
      "Epoch 40/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8379 - mae: 0.7492 - val_loss: 0.8769 - val_mae: 0.7672\n",
      "Epoch 41/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8408 - mae: 0.7502 - val_loss: 0.9160 - val_mae: 0.7877\n",
      "Epoch 42/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8532 - mae: 0.7531 - val_loss: 0.8859 - val_mae: 0.7727\n",
      "Epoch 43/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8349 - mae: 0.7434 - val_loss: 0.8791 - val_mae: 0.7630\n",
      "Epoch 44/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8305 - mae: 0.7416 - val_loss: 0.8768 - val_mae: 0.7638\n",
      "Epoch 45/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.8466 - mae: 0.7555 - val_loss: 0.8845 - val_mae: 0.7732\n",
      "Epoch 46/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8323 - mae: 0.7443 - val_loss: 0.8801 - val_mae: 0.7682\n",
      "Epoch 47/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8163 - mae: 0.7348 - val_loss: 0.8760 - val_mae: 0.7631\n",
      "Epoch 48/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8462 - mae: 0.7517 - val_loss: 0.8769 - val_mae: 0.7646\n",
      "Epoch 49/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8174 - mae: 0.7383 - val_loss: 0.8935 - val_mae: 0.7777\n",
      "Epoch 50/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8382 - mae: 0.7461 - val_loss: 0.8843 - val_mae: 0.7680\n",
      "Epoch 51/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8199 - mae: 0.7376 - val_loss: 0.8865 - val_mae: 0.7740\n",
      "Epoch 52/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8190 - mae: 0.7377 - val_loss: 0.8830 - val_mae: 0.7685\n",
      "Epoch 53/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8185 - mae: 0.7343 - val_loss: 0.8880 - val_mae: 0.7733\n",
      "Epoch 54/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8456 - mae: 0.7519 - val_loss: 0.8791 - val_mae: 0.7666\n",
      "Epoch 55/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8348 - mae: 0.7474 - val_loss: 0.8841 - val_mae: 0.7706\n",
      "Epoch 56/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8102 - mae: 0.7343 - val_loss: 0.8848 - val_mae: 0.7698\n",
      "Epoch 57/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8155 - mae: 0.7350 - val_loss: 0.8842 - val_mae: 0.7680\n",
      "Epoch 58/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8025 - mae: 0.7291 - val_loss: 0.8832 - val_mae: 0.7693\n",
      "Epoch 59/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8125 - mae: 0.7338 - val_loss: 0.8806 - val_mae: 0.7674\n",
      "Epoch 60/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8074 - mae: 0.7297 - val_loss: 0.8983 - val_mae: 0.7767\n",
      "Epoch 61/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8139 - mae: 0.7332 - val_loss: 0.8877 - val_mae: 0.7717\n",
      "Epoch 62/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8455 - mae: 0.7463 - val_loss: 0.8840 - val_mae: 0.7664\n",
      "Epoch 63/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8222 - mae: 0.7452 - val_loss: 0.8867 - val_mae: 0.7698\n",
      "Epoch 64/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8291 - mae: 0.7432 - val_loss: 0.8882 - val_mae: 0.7693\n",
      "Epoch 65/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8097 - mae: 0.7311 - val_loss: 0.8806 - val_mae: 0.7638\n",
      "Epoch 66/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8245 - mae: 0.7428 - val_loss: 0.8940 - val_mae: 0.7720\n",
      "Epoch 67/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8250 - mae: 0.7386 - val_loss: 0.8952 - val_mae: 0.7737\n",
      "Epoch 68/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8252 - mae: 0.7396 - val_loss: 0.8888 - val_mae: 0.7684\n",
      "Epoch 69/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7969 - mae: 0.7244 - val_loss: 0.8853 - val_mae: 0.7670\n",
      "Epoch 70/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8222 - mae: 0.7392 - val_loss: 0.8805 - val_mae: 0.7622\n",
      "Epoch 71/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7919 - mae: 0.7298 - val_loss: 0.8854 - val_mae: 0.7658\n",
      "Epoch 72/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8215 - mae: 0.7355 - val_loss: 0.8996 - val_mae: 0.7753\n",
      "Epoch 73/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8251 - mae: 0.7445 - val_loss: 0.8938 - val_mae: 0.7740\n",
      "Epoch 74/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8177 - mae: 0.7359 - val_loss: 0.8944 - val_mae: 0.7685\n",
      "Epoch 75/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7982 - mae: 0.7309 - val_loss: 0.9106 - val_mae: 0.7818\n",
      "Epoch 76/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8250 - mae: 0.7379 - val_loss: 0.9053 - val_mae: 0.7783\n",
      "Epoch 77/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8047 - mae: 0.7307 - val_loss: 0.8935 - val_mae: 0.7731\n",
      "Epoch 78/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8242 - mae: 0.7393 - val_loss: 0.9053 - val_mae: 0.7789\n",
      "Epoch 79/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8021 - mae: 0.7280 - val_loss: 0.9103 - val_mae: 0.7798\n",
      "Epoch 80/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8163 - mae: 0.7370 - val_loss: 0.8945 - val_mae: 0.7693\n",
      "Epoch 81/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8046 - mae: 0.7323 - val_loss: 0.8978 - val_mae: 0.7742\n",
      "Epoch 82/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7975 - mae: 0.7278 - val_loss: 0.9204 - val_mae: 0.7856\n",
      "Epoch 83/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7928 - mae: 0.7228 - val_loss: 0.8917 - val_mae: 0.7731\n",
      "Epoch 84/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8074 - mae: 0.7324 - val_loss: 0.8855 - val_mae: 0.7685\n",
      "Epoch 85/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8243 - mae: 0.7406 - val_loss: 0.8910 - val_mae: 0.7693\n",
      "Epoch 86/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8064 - mae: 0.7325 - val_loss: 0.8921 - val_mae: 0.7688\n",
      "Epoch 87/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8111 - mae: 0.7347 - val_loss: 0.9018 - val_mae: 0.7771\n",
      "Epoch 88/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8097 - mae: 0.7393 - val_loss: 0.8995 - val_mae: 0.7733\n",
      "Epoch 89/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8050 - mae: 0.7316 - val_loss: 0.8913 - val_mae: 0.7693\n",
      "Epoch 90/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7937 - mae: 0.7267 - val_loss: 0.8967 - val_mae: 0.7699\n",
      "Epoch 91/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8206 - mae: 0.7362 - val_loss: 0.9067 - val_mae: 0.7768\n",
      "Epoch 92/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.7994 - mae: 0.7269 - val_loss: 0.9058 - val_mae: 0.7809\n",
      "Epoch 93/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7881 - mae: 0.7254 - val_loss: 0.8970 - val_mae: 0.7747\n",
      "Epoch 94/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8029 - mae: 0.7303 - val_loss: 0.9000 - val_mae: 0.7719\n",
      "Epoch 95/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8060 - mae: 0.7310 - val_loss: 0.9036 - val_mae: 0.7725\n",
      "Epoch 96/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8048 - mae: 0.7315 - val_loss: 0.8975 - val_mae: 0.7679\n",
      "Epoch 97/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7911 - mae: 0.7220 - val_loss: 0.9058 - val_mae: 0.7765\n",
      "Epoch 98/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7780 - mae: 0.7147 - val_loss: 0.9015 - val_mae: 0.7737\n",
      "Epoch 99/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7885 - mae: 0.7232 - val_loss: 0.9370 - val_mae: 0.7951\n",
      "Epoch 100/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8127 - mae: 0.7313 - val_loss: 0.9076 - val_mae: 0.7783\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    callbacks=[tensorboard_cb,checkpoint_cb],\n",
    "    validation_split=0.1\n",
    ")\n",
    "#  early_stop_cb, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65d255b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('best_model.h5')\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf67f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "Predicted expected return: 4.360814571380615\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "user_input = np.array([[25, 5000, 8, 6, 5, 10, 0, 2, 0, 5, 100000, 1, 2, 1,4]])  # Example user input\n",
    "user_input_scaled = scaler.transform(user_input)  # Scale the input\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# Predict the expected return\n",
    "predicted_return = model.predict(user_input_scaled)\n",
    "print(f\"Predicted expected return: {predicted_return[0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
